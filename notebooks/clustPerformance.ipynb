{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "593043a5",
   "metadata": {},
   "source": [
    "<head>\n",
    "    <title>Arghya Dutta</title>\n",
    "    <meta charset=\"utf-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1, shrink-to-fit=no\">\n",
    "    <link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../assets/favicon_io/apple-touch-icon.png\">\n",
    "    <link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../assets/favicon_io/favicon-32x32.png\">\n",
    "    <link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../assets/favicon_io/favicon-16x16.png\">\n",
    "    <link rel=\"manifest\" href=\"../assets/favicon_io/site.webmanifest\">\n",
    "</head>\n",
    "\n",
    "<em><a href=\"../notebooks.html\">Notebooks</a></em>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3f0c89",
   "metadata": {},
   "source": [
    "\n",
    "<h1>Evaluating Clustering Performance</h1>\n",
    "\n",
    "<mark>NOTE: Most of this notebook's content is adapted—often copied!—from the [Scikit Learn's excellent documentation on clustering](https://scikit-learn.org/stable/modules/clustering.html). This is a compilation of definitions/code-snippets that I found useful while working on a project, along with some of my own thoughts.</mark>\n",
    "\n",
    "Evaluation of quality of clusters is often done in two ways: \n",
    "\n",
    "- comparing how well the predicted clusters compare with the ground truth and\n",
    "- checking if the generated clusters are consistent. \n",
    "\n",
    "- The second approach is useful if no ground truths are available. There are several coefficients that quantify the quality of clustering. \n",
    "- Some that do not need a ground truth are Silhouette coefficient, Calinski–Harabasz index, and Davies–Bouldin Index. Homogeneity Score, Completeness Score, and V Measure need a ground truth.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd325092",
   "metadata": {},
   "source": [
    "## Silhouette coefficient \n",
    "\n",
    "For a single sample it is\n",
    "\n",
    "$$\n",
    "s = \\frac{b - a}{\\max(a, b)}.\n",
    "$$\n",
    "- $a$: mean distance between a sample all other points in the *same cluster*\n",
    "- $b$: mean distance between a sample all other points in the *next nearest cluster*.\n",
    "\n",
    "$s$ takes values in $[-1,1]$ with\n",
    "- $-1$ meaning incorrect clustering,\n",
    "- 0 meaning overlapping clusters, and\n",
    "- 1 meaning highly-dense, well-separated clusters.\n",
    "\n",
    "So, a higher silhouette score means better defined clusters.\n",
    "\n",
    "**Important**: Scikit returns the mean of all Silhouette coefficients of the samples.\n",
    "\n",
    "Scikit mentions a drawback:\n",
    "\n",
    "> The Silhouette Coefficient is generally higher for convex clusters than other concepts of clusters, such as density based clusters like those obtained through DBSCAN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b70188d",
   "metadata": {},
   "source": [
    "### Calinski Harabasz Index\n",
    "\n",
    "Calinski–Harabasz index (CHI) is the ratio of the sum of between-clusters dispersion for all clusters and sum of inter-cluster dispersion for all clusters. Better-defined clusters have higher CHI value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640dfe8d",
   "metadata": {},
   "source": [
    "### Davies-Bouldin Index\n",
    "\n",
    "Surprisingly, DB *values closer to zero indicate a better partition*, unlike Calinski-Harabasz index and Silhouette coefficient.\n",
    "\n",
    "For CHI and DBI formulas, check the referenced scikit doc page.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6cf0c2",
   "metadata": {},
   "source": [
    "### Homogeneity Score\n",
    "\n",
    "Homogeneity score ($h$) is defined as\n",
    "$$\n",
    "\\begin{align*}\n",
    "&h = 1 - \\frac{H(C|K)}{H(C)}\\;\\text{where}\\\\\n",
    "&H(C) = - \\sum_{c=1}^{|C|} \\frac{n_c}{n} \\cdot \\log\\left(\\frac{n_c}{n}\\right)\\\\\n",
    "&H(C|K) = - \\sum_{c=1}^{|C|} \\sum_{k=1}^{|K|} \\frac{n_{c,k}}{n}\\cdot \\log\\left(\\frac{n_{c,k}}{n_k}\\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "- $n$: total number of samples.\n",
    "- $n_c$, $n_k$: number of samples in class $c$ and cluster $k$, respectively.\n",
    "- $n_{c,k}$: number of samples from class $c$ assigned to cluster $k$.\n",
    "\n",
    "Higher $h$ means better clusters. $h$ takes values in $[0,1]$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f55788d",
   "metadata": {},
   "source": [
    "### Completeness Score\n",
    "\n",
    "- All members of a class belongs to the same cluster.\n",
    "\t- $c = 1 - \\frac{H(K|C)}{H(K)}$\n",
    "\t- $c \\in[0,1]$. higher is better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c263dea2",
   "metadata": {},
   "source": [
    "### V-Measure\n",
    "\n",
    "- The harmonic mean of the homogeneity score and completeness scores: $v = 2 \\cdot \\frac{h \\cdot c}{h + c}$. \n",
    "- It's implemented in scikit as $v = \\frac{(1 + \\beta) \\times \\text{homogeneity} \\times \\text{completeness}}{(\\beta \\times \\text{homogeneity} + \\text{completeness})}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edf4bf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666669\n",
      "0.420619835714305\n",
      "0.5467344787062375\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "labels_true = [0, 0, 0, 1, 1, 1]\n",
    "labels_pred = [0, 0, 1, 1, 2, 2]\n",
    "\n",
    "print(metrics.homogeneity_score(labels_true, labels_pred))\n",
    "print(metrics.completeness_score(labels_true, labels_pred))\n",
    "print(metrics.v_measure_score(labels_true, labels_pred, beta=0.6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949bc442",
   "metadata": {},
   "source": [
    "### Mutual-information-based similarity score\n",
    "\n",
    "Let's say, we have 2 sets of labels, $U$ and $V$, for $N$ objects. If $P(i)=|U_i|/N$ and $P'(j)=|V_i|/N$ are the probabilities that a randomly-picked object from $U$ ($V$) falls into class $U_i$ ($V_j$), then the entropies and the mutual information between $U$ and $V$ are computed as\n",
    "$$\n",
    "\\begin{aligned}\n",
    "H(U) &= - \\sum_{i=1}^{|U|}P(i)\\log(P(i))\\\\\n",
    "H(V) &= - \\sum_{j=1}^{|V|}P'(j)\\log(P'(j))\\\\\n",
    "\\text{MI}(U, V) &= \\sum_{i=1}^{|U|}\\sum_{j=1}^{|V|}P(i, j)\\log\\left(\\frac{P(i,j)}{P(i)P'(j)}\\right)\\\\\n",
    "&= \\sum_{i=1}^{|U|} \\sum_{j=1}^{|V|} \\frac{|U_i \\cap V_j|}{N}\\log\\left(\\frac{N|U_i \\cap V_j|}{|U_i||V_j|}\\right)\\\\\n",
    "\\text{NMI}(U, V) &= \\frac{\\text{MI}(U, V)}{\\text{mean}(H(U), H(V))}\\\\\n",
    "\\text{AMI} &= \\frac{\\text{MI} - E[\\text{MI}]}{\\text{mean}(H(U), H(V)) - E[\\text{MI}]}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "- AMI is adjusted against chance. NMI and MI are not.\n",
    "- AMI\n",
    "\t- $<0$: bad (i.e. independent labeling)\n",
    "\t- $=0$ (random labeling)\n",
    "\t- $\\simeq 1$ (agreement between the ground truth and predicted labels)\n",
    "\n",
    "\n",
    "References:\n",
    "\n",
    "- C. D. Manning, P. Raghavan, H. Schütze. Introduction to Information Retrieval; Cambridge University Press: New York, 2008. pp. 356–359 (Good discussion.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19bd0cf",
   "metadata": {},
   "source": [
    "### Pair confusion matrix\n",
    "\n",
    "Two clusters can be compared using the pair-confusion Matrix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bb9108",
   "metadata": {},
   "source": [
    "![Pair Confusion matrix](../assets/images/pair-confusion.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a38fa494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8 0]\n",
      " [2 2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.cluster import pair_confusion_matrix\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "C = pair_confusion_matrix([0, 0, 1, 1], [0, 0, 1, 2])\n",
    "print(C)\n",
    "TN = C[0, 0]\n",
    "FP = C[0, 1]\n",
    "FN = C[1, 0]\n",
    "TP = C[1, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0e24ea",
   "metadata": {},
   "source": [
    "### Fowlkes–Mallows Index\n",
    "\n",
    "Building on the pair-confusion matrix, FMI, a measure for cluster similarity, is computed using the elements of $C$ as\n",
    "$$FMI = \\frac{TP}{\\sqrt{(TP + FP) (TP + FN)}}.$$\n",
    "\n",
    "FMI is useful because it gives a number—and not a matrix like the pair confusion matrix—for quickly comparing two clusterings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5fd51a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071067811865475\n",
      "0.7071067811865476\n",
      "[[8 0]\n",
      " [0 4]]\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "FMI = TP / np.sqrt((TP + FP) * (TP + FN))\n",
    "print(FMI)\n",
    "# You Can also Compute FMI Using Scikit-learn. The Results Match, of Course.\n",
    "print(metrics.fowlkes_mallows_score([0, 0, 1, 1], [0, 0, 1, 2]))\n",
    "\n",
    "# Also Two Same Partitions Will Have no Off-diagonal Elements in the Pair Confusion Matrix and a FMI Score of 1.\n",
    "\n",
    "C = pair_confusion_matrix([0, 0, 1, 1], [0, 0, 1, 1])\n",
    "print(C)\n",
    "TN = C[0, 0]\n",
    "FP = C[0, 1]\n",
    "FN = C[1, 0]\n",
    "TP = C[1, 1]\n",
    "\n",
    "FMI = TP / np.sqrt((TP + FP) * (TP + FN))\n",
    "print(FMI)\n",
    "\n",
    "print(metrics.fowlkes_mallows_score([0, 0, 1, 1], [0, 0, 1, 1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9139fcf",
   "metadata": {},
   "source": [
    "### Element-centric similarity and issues with FMI and NMI\n",
    "\n",
    "Gates et al. raise objections against using Fowlkes–Mallows Index and NMI, specifically NMI; they proposed a new one. \n",
    "\n",
    "References:\n",
    "\n",
    "- A. J. Gates et al. Element-Centric Clustering Comparison Unifies Overlaps and Hierarchy. Sci Rep 2019, 9 (1), 8574. [DOI](https://doi.org/10.1038/s41598-019-44892-y).\n",
    "- A. J. Gates, Y.-Y. Ahn. CluSim: A Python Package for Calculating Clustering Similarity. Journal of Open Source Software 2019, 4 (35), 1264. [DOI](https://doi.org/10.21105/joss.01264).\n",
    "- <https://github.com/Hoosier-Clusters/clusim> of Gates et al. with their package\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9da23bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FMI = 0.4811252243246881, NMI = 0.5451600159416435, elem-cent = 0.5407407407407406\n",
      "FMI = 0.5, NMI = 0.0, elem-cent = 0.33333333333333326\n",
      "FMI = 0.0, NMI = 0.6666666666666665, elem-cent = 0.33333333333333326\n",
      "            jaccard_index                   0.3125\n",
      "               rand_index       0.6944444444444444\n",
      "            adjrand_index      0.26666666666666655\n",
      "    fowlkes_mallows_index       0.4811252243246881\n",
      "                 fmeasure      0.47619047619047616\n",
      "             purity_index       0.7777777777777777\n",
      "     classification_error      0.22222222222222232\n",
      "        czekanowski_index      0.47619047619047616\n",
      "               dice_index      0.47619047619047616\n",
      "           sorensen_index      0.47619047619047616\n",
      "    rogers_tanimoto_index       0.5319148936170213\n",
      "          southwood_index      0.45454545454545453\n",
      "      pearson_correlation      0.00102880658436214\n",
      "         corrected_chance      0.17107186225250312\n",
      "      sample_expected_sim      0.10526315789473684\n",
      "                      nmi       0.5451600159416435\n",
      "                       mi       0.8233232815796736\n",
      "                   adj_mi       0.3410389011275906\n",
      "                      rmi       0.1464053299155769\n",
      "                       vi       1.3738364418444755\n",
      "       geometric_accuracy       0.7777777777777778\n",
      "          overlap_quality                     -0.0\n",
      "                     onmi       0.6303315236619905\n",
      "              omega_index      0.26666666666666655\n"
     ]
    }
   ],
   "source": [
    "from clusim.clustering import Clustering\n",
    "import clusim.sim as sim\n",
    "\n",
    "true_labels = [1, 1, 1, 2, 2, 2, 3, 3, 3]\n",
    "predicted_labels = [1, 2, 2, 3, 3, 1, 1, 1, 1]\n",
    "single_cluster_labels = [1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "completely_fragmented_labels = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "# Their Data is Differently Formatted.\n",
    "true_clustering = Clustering().from_membership_list(true_labels)\n",
    "predicted_clustering = Clustering().from_membership_list(predicted_labels)\n",
    "predicted_single_cluster = Clustering().from_membership_list(single_cluster_labels)\n",
    "predicted_completely_fragmented = Clustering().from_membership_list(\n",
    "    completely_fragmented_labels\n",
    ")\n",
    "\n",
    "for _ in [\n",
    "    predicted_clustering,\n",
    "    predicted_single_cluster,\n",
    "    predicted_completely_fragmented,\n",
    "]:\n",
    "    print(\n",
    " f\"FMI = {sim.fowlkes_mallows_index(true_clustering,_)}, NMI = {sim.nmi(true_clustering,_)}, elem-cent = {sim.element_sim(true_clustering,_)}\"\n",
    "    )\n",
    "# The Package Can Compute Many Scores such As... (code from Their Documentation https://hoosier-clusters.github.io/clusim/html/clusim.html)\n",
    "\n",
    "row_format2 = \"{:>25}\" * (2)\n",
    "for simfunc in sim.available_similarity_measures:\n",
    "    print(\n",
    " row_format2.format(\n",
    "     simfunc, eval(\"sim.\" + simfunc +\n",
    "\"(true_clustering, predicted_clustering)\")\n",
    " )\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
